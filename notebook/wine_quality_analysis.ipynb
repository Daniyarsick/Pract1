{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ качества вина: Машинное обучение для предсказания оценок экспертов\n",
    "\n",
    "## Оглавление\n",
    "1. [Введение](#введение)\n",
    "2. [Загрузка и первичный анализ данных](#загрузка-и-первичный-анализ-данных)\n",
    "3. [Исследовательский анализ данных (EDA)](#исследовательский-анализ-данных-eda)\n",
    "4. [Подготовка данных](#подготовка-данных)\n",
    "5. [Обучение моделей](#обучение-моделей)\n",
    "6. [Оптимизация гиперпараметров](#оптимизация-гиперпараметров)\n",
    "7. [Финальная оценка](#финальная-оценка)\n",
    "8. [Выводы](#выводы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки успешно импортированы!\n"
     ]
    }
   ],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Настройка отображения\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Библиотеки успешно импортированы!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Введение\n",
    "\n",
    "В данной работе мы анализируем датасет качества вина, содержащий химические показатели красных и белых вин, а также оценки качества экспертами по шкале от 3 до 9.\n",
    "\n",
    "**Цель исследования:** Построить модель машинного обучения для предсказания качества вина на основе его химических характеристик.\n",
    "\n",
    "**Источник данных:** [Wine Quality Dataset](https://www.kaggle.com/datasets/yasserh/wine-quality-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/winequality-red.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Загрузка данных\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Предполагается, что файлы находятся в папке data/\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m red_wine = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../data/winequality-red.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m white_wine = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m../data/winequality-white.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Добавляем тип вина\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\miniconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/winequality-red.csv'"
     ]
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "# Предполагается, что файлы находятся в папке data/\n",
    "red_wine = pd.read_csv('../data/winequality-red.csv')\n",
    "white_wine = pd.read_csv('../data/winequality-white.csv')\n",
    "\n",
    "# Добавляем тип вина\n",
    "red_wine['wine_type'] = 'red'\n",
    "white_wine['wine_type'] = 'white'\n",
    "\n",
    "# Объединяем датасеты\n",
    "wine_data = pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "\n",
    "print(f\"Общий размер датасета: {wine_data.shape}\")\n",
    "print(f\"Красное вино: {len(red_wine)} образцов\")\n",
    "print(f\"Белое вино: {len(white_wine)} образцов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ИНФОРМАЦИЯ О ДАТАСЕТЕ ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wine_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Первичный анализ структуры данных\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== ИНФОРМАЦИЯ О ДАТАСЕТЕ ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mРазмерность: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mwine_data\u001b[49m.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mТипы данных:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(wine_data.dtypes)\n",
      "\u001b[31mNameError\u001b[39m: name 'wine_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Первичный анализ структуры данных\n",
    "print(\"=== ИНФОРМАЦИЯ О ДАТАСЕТЕ ===\")\n",
    "print(f\"Размерность: {wine_data.shape}\")\n",
    "print(f\"\\nТипы данных:\")\n",
    "print(wine_data.dtypes)\n",
    "print(f\"\\nПропущенные значения:\")\n",
    "print(wine_data.isnull().sum())\n",
    "print(f\"\\nСтатистическое описание:\")\n",
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ целевой переменной\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Распределение качества\n",
    "plt.subplot(1, 3, 1)\n",
    "wine_data['quality'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Распределение оценок качества вина')\n",
    "plt.xlabel('Качество')\n",
    "plt.ylabel('Количество образцов')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Распределение по типам вина\n",
    "plt.subplot(1, 3, 2)\n",
    "wine_data['wine_type'].value_counts().plot(kind='bar', color=['red', 'white'])\n",
    "plt.title('Распределение по типам вина')\n",
    "plt.xlabel('Тип вина')\n",
    "plt.ylabel('Количество образцов')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Качество по типам вина\n",
    "plt.subplot(1, 3, 3)\n",
    "quality_by_type = wine_data.groupby(['wine_type', 'quality']).size().unstack(fill_value=0)\n",
    "quality_by_type.plot(kind='bar', stacked=True)\n",
    "plt.title('Качество по типам вина')\n",
    "plt.xlabel('Тип вина')\n",
    "plt.ylabel('Количество образцов')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Качество', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Статистика по качеству\n",
    "print(\"\\n=== СТАТИСТИКА ПО КАЧЕСТВУ ===\")\n",
    "print(wine_data['quality'].value_counts().sort_index())\n",
    "print(f\"\\nСреднее качество: {wine_data['quality'].mean():.2f}\")\n",
    "print(f\"Медиана качества: {wine_data['quality'].median():.2f}\")\n",
    "print(f\"Стандартное отклонение: {wine_data['quality'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследовательский анализ данных (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корреляционный анализ\n",
    "# Создаем числовую копию данных для корреляции\n",
    "wine_numeric = wine_data.copy()\n",
    "wine_numeric['wine_type_red'] = (wine_numeric['wine_type'] == 'red').astype(int)\n",
    "wine_numeric = wine_numeric.drop('wine_type', axis=1)\n",
    "\n",
    "# Матрица корреляции\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = wine_numeric.corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Матрица корреляции химических показателей вина')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Корреляция с целевой переменной\n",
    "quality_corr = correlation_matrix['quality'].abs().sort_values(ascending=False)\n",
    "print(\"\\n=== КОРРЕЛЯЦИЯ С КАЧЕСТВОМ (по модулю) ===\")\n",
    "for feature, corr in quality_corr.items():\n",
    "    if feature != 'quality':\n",
    "        print(f\"{feature:<25}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ распределений признаков\n",
    "numeric_features = wine_numeric.columns.drop(['quality', 'wine_type_red'])\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(numeric_features):\n",
    "    # Гистограмма\n",
    "    axes[idx].hist(wine_numeric[feature], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_title(f'Распределение {feature}')\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Частота')\n",
    "    \n",
    "    # Добавляем статистики\n",
    "    mean_val = wine_numeric[feature].mean()\n",
    "    median_val = wine_numeric[feature].median()\n",
    "    axes[idx].axvline(mean_val, color='red', linestyle='--', label=f'Среднее: {mean_val:.2f}')\n",
    "    axes[idx].axvline(median_val, color='green', linestyle='--', label=f'Медиана: {median_val:.2f}')\n",
    "    axes[idx].legend()\n",
    "\n",
    "# Удаляем лишние подплоты\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ выбросов\n",
    "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "axes = axes.ravel()\n",
    "\n",
    "outlier_stats = {}\n",
    "\n",
    "for idx, feature in enumerate(numeric_features):\n",
    "    # Boxplot\n",
    "    axes[idx].boxplot(wine_numeric[feature])\n",
    "    axes[idx].set_title(f'Выбросы в {feature}')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "    \n",
    "    # Вычисляем статистику выбросов по IQR\n",
    "    Q1 = wine_numeric[feature].quantile(0.25)\n",
    "    Q3 = wine_numeric[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = wine_numeric[(wine_numeric[feature] < lower_bound) | \n",
    "                          (wine_numeric[feature] > upper_bound)][feature]\n",
    "    outlier_stats[feature] = {\n",
    "        'count': len(outliers),\n",
    "        'percentage': len(outliers) / len(wine_numeric) * 100,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    }\n",
    "\n",
    "# Удаляем лишние подплоты\n",
    "for idx in range(len(numeric_features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выводим статистику выбросов\n",
    "print(\"\\n=== СТАТИСТИКА ВЫБРОСОВ (метод IQR) ===\")\n",
    "for feature, stats in outlier_stats.items():\n",
    "    print(f\"{feature:<25}: {stats['count']:>4} ({stats['percentage']:>5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка признаков и целевой переменной\n",
    "X = wine_numeric.drop('quality', axis=1)\n",
    "y = wine_numeric['quality']\n",
    "\n",
    "# Стратифицированное разделение данных\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 ≈ 0.15/0.85\n",
    ")\n",
    "\n",
    "print(\"=== РАЗДЕЛЕНИЕ ДАННЫХ ===\")\n",
    "print(f\"Обучающая выборка: {X_train.shape[0]} образцов ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Валидационная выборка: {X_val.shape[0]} образцов ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"Тестовая выборка: {X_test.shape[0]} образцов ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Проверяем распределение классов\n",
    "print(\"\\nРаспределение классов:\")\n",
    "print(\"Обучающая:\", y_train.value_counts().sort_index().values)\n",
    "print(\"Валидационная:\", y_val.value_counts().sort_index().values)\n",
    "print(\"Тестовая:\", y_test.value_counts().sort_index().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабирование признаков\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Преобразуем обратно в DataFrame для удобства\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_val.columns, index=X_val.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"=== МАСШТАБИРОВАНИЕ ПРИЗНАКОВ ===\")\n",
    "print(\"Применен StandardScaler\")\n",
    "print(f\"Средние значения после масштабирования (должны быть ~0):\")\n",
    "print(X_train_scaled.mean().round(6))\n",
    "print(f\"\\nСтандартные отклонения после масштабирования (должны быть ~1):\")\n",
    "print(X_train_scaled.std().round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline модели\n",
    "models = {\n",
    "    'DummyClassifier': DummyClassifier(strategy='most_frequent', random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "print(\"=== ОБУЧЕНИЕ BASELINE МОДЕЛЕЙ ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nОбучение {name}...\")\n",
    "    \n",
    "    # Обучение\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Метрики\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"  Переобучение: {train_accuracy - val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Продвинутые модели\n",
    "advanced_models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "advanced_results = {}\n",
    "\n",
    "print(\"\\n=== ОБУЧЕНИЕ ПРОДВИНУТЫХ МОДЕЛЕЙ ===\")\n",
    "for name, model in advanced_models.items():\n",
    "    print(f\"\\nОбучение {name}...\")\n",
    "    \n",
    "    # Обучение с измерением времени\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Предсказания\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_val = model.predict(X_val_scaled)\n",
    "    \n",
    "    # Метрики\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    \n",
    "    # Кросс-валидация\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    advanced_results[name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Val Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"  CV Mean ± Std: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "    print(f\"  Training Time: {training_time:.2f}s\")\n",
    "    print(f\"  Переобучение: {train_accuracy - val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Оптимизация гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель для тюнинга\n",
    "best_model_name = max(advanced_results.keys(), \n",
    "                     key=lambda x: advanced_results[x]['val_accuracy'])\n",
    "print(f\"Лучшая модель для тюнинга: {best_model_name}\")\n",
    "print(f\"Валидационная точность: {advanced_results[best_model_name]['val_accuracy']:.4f}\")\n",
    "\n",
    "# Определяем параметры для тюнинга в зависимости от модели\n",
    "if best_model_name == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "    base_model = xgb.XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
    "    \n",
    "elif best_model_name == 'RandomForest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "    base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    \n",
    "else:\n",
    "    param_grid = {}\n",
    "    base_model = advanced_models[best_model_name]\n",
    "\n",
    "# Выполняем тюнинг\n",
    "if param_grid:\n",
    "    print(f\"\\nВыполняем тюнинг гиперпараметров для {best_model_name}...\")\n",
    "    \n",
    "    # Используем RandomizedSearchCV для экономии времени\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model, param_grid, n_iter=50, cv=3, \n",
    "        scoring='accuracy', random_state=42, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Лучшая модель\n",
    "    best_model = random_search.best_estimator_\n",
    "    print(f\"\\nЛучшие параметры: {random_search.best_params_}\")\n",
    "    print(f\"Лучший CV score: {random_search.best_score_:.4f}\")\n",
    "    \n",
    "else:\n",
    "    best_model = advanced_models[best_model_name]\n",
    "    print(f\"Используем модель {best_model_name} без дополнительного тюнинга\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Финальная оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Финальная оценка на тестовой выборке\n",
    "y_test_pred = best_model.predict(X_test_scaled)\n",
    "y_test_proba = best_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Метрики\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"=== ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ ===\")\n",
    "print(f\"Модель: {best_model_name}\")\n",
    "print(f\"Точность на тестовой выборке: {test_accuracy:.4f}\")\n",
    "\n",
    "# Подробный отчет по классификации\n",
    "print(f\"\\nОтчет по классификации:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Матрица ошибок\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=sorted(y.unique()),\n",
    "            yticklabels=sorted(y.unique()))\n",
    "plt.title('Матрица ошибок')\n",
    "plt.xlabel('Предсказанное качество')\n",
    "plt.ylabel('Реальное качество')\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC для многоклассовой классификации\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba, multi_class='ovr')\n",
    "print(f\"\\nROC AUC (One-vs-Rest): {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важность признаков\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "    plt.title('Важность признаков')\n",
    "    plt.xlabel('Важность')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=== ВАЖНОСТЬ ПРИЗНАКОВ ===\")\n",
    "    for idx, row in feature_importance.iterrows():\n",
    "        print(f\"{row['feature']:<25}: {row['importance']:.4f}\")\n",
    "\n",
    "# Сохранение модели\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(best_model, '../models/best_wine_model.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "\n",
    "# Сохранение метаданных модели\n",
    "import json\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'roc_auc': float(roc_auc),\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'classes': list(sorted(y.unique())),\n",
    "    'training_size': len(X_train),\n",
    "    'features_count': len(X_train.columns)\n",
    "}\n",
    "\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nМодель сохранена в ../models/best_wine_model.pkl\")\n",
    "print(f\"Скейлер сохранен в ../models/scaler.pkl\")\n",
    "print(f\"Метаданные сохранены в ../models/model_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Выводы\n",
    "\n",
    "### Основные результаты:\n",
    "\n",
    "1. **Качество данных**: Датасет содержит 6497 образцов вина без пропущенных значений\n",
    "2. **Дисбаланс классов**: Большинство вин имеют качество 5-6 баллов\n",
    "3. **Лучшая модель**: Достигнута точность {test_accuracy:.1%} на тестовой выборке\n",
    "4. **Важные признаки**: Содержание алкоголя и летучая кислотность наиболее влияют на качество\n",
    "\n",
    "### Рекомендации:\n",
    "\n",
    "1. Собрать больше данных для редких классов качества (3-4, 8-9)\n",
    "2. Рассмотреть использование методов работы с несбалансированными данными\n",
    "3. Добавить дополнительные признаки (регион, год урожая, сорт винограда)\n",
    "4. Исследовать ансамблевые методы для улучшения качества предсказаний\n",
    "\n",
    "### Практическое применение:\n",
    "\n",
    "Модель может быть использована виноделами для:\n",
    "- Контроля качества в процессе производства\n",
    "- Оптимизации химического состава вина\n",
    "- Предварительной оценки качества перед дегустацией экспертами"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
